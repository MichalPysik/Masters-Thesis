---- Embedding ----

# benchmark (CLIP-based only) https://www.marqo.ai/blog/benchmarking-models-for-multimodal-search

* OpenAI CLIP - ANO (kdyztak 2 verze - ["openai/clip-vit-base-patch32", "openai/clip-vit-large-patch14"])

* Microsoft Florence 2 - SPISE NE, nelze extrahovat embeddingy

* Microsoft Kosmos-2 - SPISE NE, pouziva clip-l/14

* Meta ImageBind - NE, je jen extending clip na vice modalit

* OpenCLIP - laion2b_s34b_b79k, ViT-H-14/ViT-bigG-14 - SPISE NE

* Google SigLIP - ANO ("google/siglip-so400m-patch14-384")

* SalesForce BLIP-2 - SPISE NE (malo VRAM)

* SalesForce BLIP - ANO, skrze https://github.com/salesforce/LAVIS?tab=readme-ov-file (vyzaduje rust compiler 1.72.0)

* ImageBERT

* VisualBERT

* LXMERT

* UNITER

* GOOGLE ALIGN - ANO ("kakaobrain/align-base")

* Colpali - ASI NE, malo VRAM, 1024 patches x 128 embedding












---- MLLM ----
